# KrishiSahay - AI-Powered Agricultural Assistant

A full-stack, production-ready web application that helps Indian farmers with agricultural queries. Features multilingual support (all major Indian languages), offline-capable AI, mixed-language understanding, region/season-aware responses, and image analysis.

## ğŸŒ¾ Features

### Core Features
- **AI-Powered Responses**: Multiple AI backends (Ollama offline AI, RAG pipeline, mock fallback)
- **All Indian Languages**: Hindi, Telugu, Tamil, Bengali, Marathi, Gujarati, Kannada, Malayalam, Odia, Punjabi, Assamese, Urdu, English
- **Mixed Language Support**: Understands code-mixing (e.g., Telugu + English, Hindi + English)
- **Region & Season Aware**: Automatically adapts answers based on user's location and current season (Kharif/Rabi/Zaid)
- **Offline Capable**: Works with Ollama (local LLM) for offline AI responses
- **Image Analysis**: Upload crop/pest/disease images for ML-powered analysis
- **Voice Input**: Browser-based speech recognition
- **Text-to-Speech**: Listen to answers in your language
- **Fast Response**: <2 seconds average response time with caching

### Advanced Features
- **Supabase Integration**: Cloud database with MySQL fallback
- **RAG Pipeline**: FAISS vector search with Sentence Transformers
- **ML Model Repository**: Separate repository for advanced ML models
- **PWA Ready**: Installable on mobile devices
- **Offline Caching**: Responses cached for offline access

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 18** with TypeScript
- **Vite** (build tool)
- **Tailwind CSS** (styling)
- **Lucide React** (icons)
- **Supabase JS** (database client)

### Backend
- **FastAPI** (async Python web framework)
- **Ollama** (offline-capable local LLM)
- **FAISS** (vector similarity search)
- **Sentence Transformers** (embeddings)
- **Supabase** (primary database) with MySQL fallback
- **Pillow** (image processing)
- **Transformers** (ML models)

## ğŸ“‹ Prerequisites

- **Node.js 18+** and npm
- **Python 3.7+** (3.8+ recommended for ML features)
- **pip** (Python package manager)
- **Ollama** (optional, for offline AI) - [Install Ollama](https://ollama.ai)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <repository-url>
cd project
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables (optional)
# Copy backend/.env.example to backend/.env and fill in Supabase credentials

# Start the backend server
python main.py
```

The backend will run on `http://localhost:8000`

**Optional: Setup Ollama for Offline AI**
```bash
# Install Ollama from https://ollama.ai
# Then run:
ollama run llama3.2
# Or: ollama run mistral
```

### 3. Frontend Setup

```bash
# Navigate to project root
cd ..

# Install dependencies
npm install

# Configure environment variables
# Copy .env.example to .env and fill in:
# - VITE_SUPABASE_URL
# - VITE_SUPABASE_ANON_KEY
# - VITE_API_URL=/api (for dev proxy)

# Start development server
npm run dev
```

The frontend will run on `http://localhost:5173` (or next available port)

### 4. Access the Application

Open your browser and navigate to `http://localhost:5173`

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ model.py                # RAG pipeline with FAISS
â”‚   â”œâ”€â”€ database.py             # Supabase/MySQL database manager
â”‚   â”œâ”€â”€ utils.py                # Translation & language detection
â”‚   â”œâ”€â”€ context_utils.py        # Region/season utilities
â”‚   â”œâ”€â”€ ollama_client.py        # Offline AI client
â”‚   â”œâ”€â”€ ml_model.py             # ML model for image classification
â”‚   â”œâ”€â”€ image_analyzer.py       # Image analysis with ML
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env                    # Environment variables (create from .env.example)
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ agricultural_knowledge.json
â”œâ”€â”€ ml-model-repo/              # Separate ML model repository
â”‚   â”œâ”€â”€ data.py                 # Agricultural knowledge dataset
â”‚   â”œâ”€â”€ model.py                # FAISS index builder
â”‚   â”œâ”€â”€ query.py                # Query system
â”‚   â”œâ”€â”€ rag_pipeline.py        # Full RAG pipeline
â”‚   â”œâ”€â”€ model_simple.py         # Simple version (no FAISS)
â”‚   â”œâ”€â”€ query_simple.py         # Simple query (numpy-based)
â”‚   â””â”€â”€ rag_simple.py           # Simple RAG (template-based)
â”œâ”€â”€ supabase/
â”‚   â””â”€â”€ migrations/             # Database migrations
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”œâ”€â”€ pages/                  # Page components
â”‚   â”œâ”€â”€ services/               # API service layer
â”‚   â”œâ”€â”€ hooks/                  # Custom React hooks
â”‚   â””â”€â”€ App.tsx                 # Main app component
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ manifest.json           # PWA manifest
â”‚   â””â”€â”€ sw.js                   # Service worker
â”œâ”€â”€ .env                        # Frontend environment variables
â””â”€â”€ package.json                # Node.js dependencies
```

## ğŸ”§ Configuration

### Environment Variables

**Frontend** (`.env` in project root):
```env
# API base URL - use /api in dev (proxied to backend)
VITE_API_URL=/api

# Supabase (for frontend + backend)
VITE_SUPABASE_URL=https://your-project-id.supabase.co
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key
```

**Backend** (`backend/.env`):
```env
# Supabase (primary database)
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_ANON_KEY=your_supabase_anon_key
# Or: SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# MySQL (fallback when Supabase not configured)
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=your_password
MYSQL_DB=krishisahay

# Offline AI (Ollama)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

### Supabase Setup

1. Create a Supabase project at [supabase.com](https://supabase.com)
2. Run migration: Copy `supabase/migrations/20260220020000_create_krishisahay_tables.sql` to Supabase SQL Editor and execute
3. Add credentials to `.env` files

See `SUPABASE_SETUP.md` for detailed instructions.

## ğŸ“š API Endpoints

### POST /ask
Ask an agricultural question with region/season context.

**Request:**
```json
{
  "query": "How to control pests in rice?",
  "language": "en",
  "region": "Telangana",
  "season": "Kharif",
  "lat": 17.3850,
  "lon": 78.4867
}
```

**Response:**
```json
{
  "answer": "For pest control in rice during Kharif season in Telangana...",
  "source": "ollama",
  "category": "Pest Management"
}
```

### POST /analyze-image
Analyze agricultural image (crops, pests, diseases).

**Request:** Multipart form data with `image`, `language`, `query` (optional)

**Response:**
```json
{
  "answer": "ML model detected: pest (confidence: 0.85)...",
  "source": "image_analysis",
  "category": "Pest Management"
}
```

### POST /feedback
Submit feedback on an answer.

### POST /app-feedback
Submit general app feedback with rating.

### GET /health
Health check endpoint with system status.

## ğŸŒ Language Support

### Supported Languages
- **English** (en)
- **Hindi** (hi) - à¤¹à¤¿à¤‚à¤¦à¥€
- **Telugu** (te) - à°¤à±†à°²à±à°—à±
- **Tamil** (ta) - à®¤à®®à®¿à®´à¯
- **Bengali** (bn) - à¦¬à¦¾à¦‚à¦²à¦¾
- **Marathi** (mr) - à¤®à¤°à¤¾à¤ à¥€
- **Gujarati** (gu) - àª—à«àªœàª°àª¾àª¤à«€
- **Kannada** (kn) - à²•à²¨à³à²¨à²¡
- **Malayalam** (ml) - à´®à´²à´¯à´¾à´³à´‚
- **Odia** (or) - à¬“à¬¡à¬¼à¬¿à¬†
- **Punjabi** (pa) - à¨ªà©°à¨œà¨¾à¨¬à©€
- **Assamese** (as) - à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾
- **Urdu** (ur) - Ø§Ø±Ø¯Ùˆ
- **Mixed** - Any Indian language + English code-mixing

### Mixed Language Examples
- "rice pests ela control cheyam" (Telugu + English)
- "à¤•à¥€à¤Ÿ à¤•à¥ˆà¤¸à¥‡ control à¤•à¤°à¥‡à¤‚" (Hindi + English)
- "paddy lo diseases ela prevent cheyam" (Telugu + English)

## ğŸ§ª Testing

### Test Backend

```bash
cd backend
python main.py
# In another terminal:
curl http://localhost:8000/health
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "How to grow rice?", "language": "en"}'
```

### Test Frontend

```bash
npm run dev
# Open http://localhost:5173
```

### Test ML Model Repository

```bash
cd ml-model-repo
python model_simple.py
python query_simple.py
python rag_simple.py
```

## ğŸ³ Docker Support (Optional)

Create `Dockerfile`:

```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY backend/requirements.txt .
RUN pip install -r requirements.txt
COPY backend/ .
CMD ["python", "main.py"]
```

Build and run:
```bash
docker build -t krishisahay-backend .
docker run -p 8000:8000 krishisahay-backend
```

## ğŸ“± PWA Installation

1. Open the application in a mobile browser
2. Look for "Add to Home Screen" option
3. Install the app
4. The app will work offline with cached responses

## ğŸ” Troubleshooting

### Backend Issues

**FAISS index not found:**
- Not required - system uses mock/RAG/Ollama fallback
- To build: `cd backend && python setup_faiss.py`

**Ollama not working:**
- Install Ollama from https://ollama.ai
- Run: `ollama run llama3.2`
- Check: `curl http://localhost:11434/api/tags`

**Port already in use:**
- Change port in `backend/main.py` or kill process using port 8000

**Supabase connection failed:**
- Check `.env` files have correct credentials
- Verify migration ran successfully
- System falls back to MySQL if Supabase unavailable

### Frontend Issues

**API connection failed:**
- Ensure backend is running on port 8000
- Check `VITE_API_URL` in `.env` file (use `/api` for dev)
- Check CORS settings in `backend/main.py`

**Service Worker not working:**
- Clear browser cache
- Check browser console for errors
- Ensure HTTPS in production

## ğŸš€ Production Deployment

### Backend

1. Use a production ASGI server:
```bash
pip install gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
```

2. Set up reverse proxy (nginx/Apache)
3. Configure environment variables
4. Use Supabase (already configured) or PostgreSQL

### Frontend

1. Build for production:
```bash
npm run build
```

2. Serve `dist/` folder with a web server
3. Ensure HTTPS for PWA features
4. Update `VITE_API_URL` to production backend URL

## ğŸ“ Adding More Knowledge

To add more agricultural knowledge:

1. Edit `backend/data/agricultural_knowledge.json`
2. Add new documents in the same format
3. Rebuild FAISS index (optional): `cd backend && python setup_faiss.py`
4. Or use Ollama/RAG which doesn't require rebuilding

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- **Ollama** for offline-capable AI
- **Sentence Transformers** for embeddings
- **FAISS** for efficient vector search
- **FastAPI** for the async backend framework
- **React and Vite** for the frontend framework
- **Supabase** for database infrastructure

## ğŸ“ Support

For issues and questions, please open an issue on GitHub.

---

**Built with â¤ï¸ for Indian farmers**
